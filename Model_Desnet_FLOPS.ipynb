{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model DenseNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy\n",
    "\n",
    "class channel_selection(nn.Module):\n",
    "    \"\"\"\n",
    "    Select channels from the output of BatchNorm2d layer. It should be put directly after BatchNorm2d layer.\n",
    "    The output shape of this layer is determined by the number of 1 in `self.indexes`.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_channels):\n",
    "        \"\"\"\n",
    "        Initialize the `indexes` with all one vector with the length same as the number of channels.\n",
    "        During pruning, the places in `indexes` which correpond to the channels to be pruned will be set to 0.\n",
    "        \"\"\"\n",
    "        super(channel_selection, self).__init__()\n",
    "        self.indexes = nn.Parameter(torch.ones(num_channels))\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        \"\"\"\n",
    "        Parameter\n",
    "        ---------\n",
    "        input_tensor: (N,C,H,W). It should be the output of BatchNorm2d layer.\n",
    "        \"\"\"\n",
    "        selected_index = np.squeeze(np.argwhere(self.indexes.data.cpu().numpy()))\n",
    "        if selected_index.size == 1:\n",
    "            selected_index = np.resize(selected_index, (1,)) \n",
    "        output = input_tensor[:, selected_index, :, :]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, inplanes, cfg, growthRate=12, dropRate=0):\n",
    "        \"\"\"\n",
    "        :param inplanes: input channel size\n",
    "        :param cfg: `in_planes` equals `cfg`\n",
    "        :param growthRate: output channel size = `in_planes` + growthRate\n",
    "        :param dropRate: dropout rate\n",
    "        \"\"\"\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.select = channel_selection(inplanes)\n",
    "        self.conv1 = nn.Conv2d(cfg, growthRate, kernel_size=3, padding=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropRate = dropRate\n",
    "\n",
    "    def mask_bn(self, cfg_mask):\n",
    "        self.bn1.weight.data.mul_(cfg_mask)\n",
    "        self.bn1.bias.data.mul_(cfg_mask)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bn1(x)\n",
    "        out = self.select(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "        if self.dropRate > 0:\n",
    "            out = F.dropout(out, p=self.dropRate, training=self.training)\n",
    "        out = torch.cat((x, out), 1)\n",
    "        return out\n",
    "\n",
    "    def forward_bn(self, x):\n",
    "        out = self.bn1(x)\n",
    "        bn_value = out.clone()\n",
    "        out = self.select(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "        if self.dropRate > 0:\n",
    "            out = F.dropout(out, p=self.dropRate, training=self.training)\n",
    "        out = torch.cat((x, out), 1)\n",
    "        return out, bn_value\n",
    "\n",
    "\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, inplanes, outplanes, cfg):\n",
    "        \"\"\"\n",
    "        :param inplanes: number of the input channel\n",
    "        :param outplanes: number of the output channel\n",
    "        :param cfg: `out_planes` equals `cfg`\n",
    "        \"\"\"\n",
    "        super(Transition, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.select = channel_selection(inplanes)\n",
    "        self.conv1 = nn.Conv2d(cfg, outplanes, kernel_size=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def mask_bn(self, cfg_mask):\n",
    "        self.bn1.weight.data.mul_(cfg_mask)\n",
    "        self.bn1.bias.data.mul_(cfg_mask)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bn1(x)\n",
    "        out = self.select(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        return out\n",
    "\n",
    "    def forward_bn(self, x):\n",
    "        out = self.bn1(x)\n",
    "        bn_value = out.clone()\n",
    "        out = self.select(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        return out, bn_value\n",
    "\n",
    "\n",
    "\n",
    "class densenet(nn.Module):\n",
    "\n",
    "    def __init__(self, depth=40, dropRate=0, dataset='cifar10',\n",
    "                 growthRate=12, compressionRate=1, cfg=None, conv_cfg=None):\n",
    "        \"\"\"\n",
    "        :param depth: 3 (layers) × n (number of conv2ds / layer) + 4 (Conv2ds)\n",
    "        :param drop_rate: dropout rate\n",
    "        :param dataset: cifar10 or cifar100\n",
    "        :param growth_rate: gradually increasing from the `n` conv2d to the `n+1` conv2d / layer\n",
    "        :param cfg:\n",
    "           default cfg is None:\n",
    "               start = 24, len(cfg) = 3, growth_rate = 12, cfg.shape = [3, 12 + 1]\n",
    "               cfg[0] = [24(start), 36, 48, 60, 72, ..., 168]\n",
    "               cfg[1] = [168(start), 170, 182, 194, ..., 312]\n",
    "               cfg[2] = [312(start), 324, 336, 348, ..., 456]\n",
    "        :param conv_cfg:\n",
    "            layer block index examples: (index starts at 1 & ≤ 12):\n",
    "                3 indexes / layer: [3, 6, 9]\n",
    "                2 indexes / layer: [4, 8]\n",
    "                1 index / layer: [6]\n",
    "\n",
    "        model 40 conv2ds' distribution:\n",
    "           1 conv2d\n",
    "           dense block 1 (12 conv2ds)\n",
    "           trans block 1 (1 conv2d)\n",
    "           dense block 2 (12 conv2ds)\n",
    "           trans block 2 (1 conv2d)\n",
    "           dense block 3 (12 conv2ds)\n",
    "           1 conv2d\n",
    "       \"\"\"\n",
    "        super(densenet, self).__init__()\n",
    "\n",
    "        assert (depth - 4) % 3 == 0, 'depth should be 3n+4'\n",
    "        n = (depth - 4) // 3\n",
    "        block = BasicBlock\n",
    "\n",
    "        self.growthRate = growthRate\n",
    "        self.dropRate = dropRate\n",
    "        self.block_cfg = conv_cfg\n",
    "\n",
    "        if cfg is None:\n",
    "            cfg = []\n",
    "            start = growthRate * 2\n",
    "            for _ in range(3):\n",
    "                cfg.append([start + growthRate * i for i in range(n + 1)])\n",
    "                start += growthRate * n\n",
    "            cfg = [item for sub_list in cfg for item in sub_list]\n",
    "        assert len(cfg) == 3 * n + 3, 'length of config variable cfg should be 3n+3'\n",
    "\n",
    "        # self.inplanes is a global variable used across multiple\n",
    "        self.inplanes = growthRate * 2\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, padding=1, bias=False)\n",
    "        self.dense1 = self._make_dense_block(block, n, cfg[0:n])\n",
    "        self.trans1 = self._make_transition(compressionRate, cfg[n])\n",
    "        self.dense2 = self._make_dense_block(block, n, cfg[n + 1:2 * n + 1])\n",
    "        self.trans2 = self._make_transition(compressionRate, cfg[2 * n + 1])\n",
    "        self.dense3 = self._make_dense_block(block, n, cfg[2 * n + 2:3 * n + 2])\n",
    "        self.bn = nn.BatchNorm2d(self.inplanes)\n",
    "        self.select = channel_selection(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.avgpool = nn.AvgPool2d(8)\n",
    "\n",
    "        # model dataset\n",
    "        if dataset == 'cifar10':\n",
    "            num_classes = 10\n",
    "        elif dataset == 'cifar100':\n",
    "            num_classes = 100\n",
    "        else:\n",
    "            raise ValueError('Model `dataset` parameter is Error!')\n",
    "        self.fc = nn.Linear(cfg[-1], num_classes)\n",
    "\n",
    "        # weight initialize\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(0.5)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_dense_block(self, block, blocks, cfg):\n",
    "        \"\"\"\n",
    "        :param block: Basic Block (1 block means 1 conv2d)\n",
    "        :param blocks: number of blocks (n) / layer\n",
    "        :param cfg: channel config of all blocks / layer\n",
    "        \"\"\"\n",
    "        layers = []\n",
    "        assert blocks == len(cfg), 'Length of the cfg parameter is not right.'\n",
    "        for i in range(blocks):\n",
    "            layers.append(block(self.inplanes, cfg=cfg[i], growthRate=self.growthRate, dropRate=self.dropRate))\n",
    "            self.inplanes += self.growthRate\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_transition(self, compressionRate, cfg):\n",
    "        \"\"\"\n",
    "        :param compressionRate: compress input channel\n",
    "        :param cfg:\n",
    "                    input channel size, `cfg` equals `in_planes`\n",
    "                    cfg is a number in this case\n",
    "        \"\"\"\n",
    "        inplanes = self.inplanes\n",
    "        outplanes = int(math.floor(self.inplanes // compressionRate))\n",
    "        self.inplanes = outplanes\n",
    "        return Transition(inplanes, outplanes, cfg)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        block_value = []\n",
    "        if self.block_cfg:\n",
    "            for idx, item in enumerate(self.dense1):\n",
    "                x = item(x)\n",
    "                if idx + 1 in self.block_cfg:\n",
    "                    block_value.append(x.clone())\n",
    "            x = self.trans1(x)\n",
    "            for idx, item in enumerate(self.dense2):\n",
    "                x = item(x)\n",
    "                if idx + 1 in self.block_cfg:\n",
    "                    block_value.append(x.clone())\n",
    "            x = self.trans2(x)\n",
    "            for idx, item in enumerate(self.dense3):\n",
    "                x = item(x)\n",
    "                if idx + 1 in self.block_cfg:\n",
    "                    block_value.append(x.clone())\n",
    "        else:\n",
    "            x = self.dense1(x)\n",
    "            x = self.trans1(x)\n",
    "            x = self.dense2(x)\n",
    "            x = self.trans2(x)\n",
    "            x = self.dense3(x)\n",
    "\n",
    "        x = self.bn(x)\n",
    "        x = self.select(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y = self.fc(x)\n",
    "\n",
    "        if len(block_value):\n",
    "            return y, block_value\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'D:\\Project\\Gitee\\network-slimming\\logs\\at_prune_densenet40_cifar100_percent_0.6\\pruned.pt'\n",
      "-> model cfg is loading...\n",
      " cfg: [21, 25, 22, 29, 40, 39, 43, 53, 58, 53, 53, 57, 71, 83, 81, 78, 87, 95, 93, 96, 97, 100, 100, 110, 113, 72, 137, 158, 165, 156, 162, 156, 153, 141, 141, 145, 144, 147, 169]\n",
      "=>  epoch None Prec1: None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def resume_model(resume_file):\n",
    "    if not os.path.isfile(resume_file):\n",
    "        raise ValueError(\"Resume model file is not found at '{}'\".format(resume_file))\n",
    "    print(\"=> loading checkpoint '{}'\".format(resume_file))\n",
    "    checkpoint = torch.load(resume_file)\n",
    "    if 'epoch' in checkpoint:\n",
    "        start_epoch = checkpoint['epoch']\n",
    "    else:\n",
    "        start_epoch = None\n",
    "        \n",
    "    if 'best_prec1' in checkpoint:\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "    else:\n",
    "        best_prec1 = None\n",
    "        \n",
    "    if 'state_dict' in checkpoint:\n",
    "        state_dict = checkpoint['state_dict']\n",
    "    else:\n",
    "        state_dict = None\n",
    "    \n",
    "    if 'optimizer' in checkpoint:\n",
    "        opti_dict = checkpoint['optimizer']\n",
    "    else:\n",
    "        opti_dict = None\n",
    "        \n",
    "    if 'cfg' in checkpoint:\n",
    "        cfg = checkpoint['cfg']\n",
    "        print(\"-> model cfg is loading...\\n cfg: {}\".format(list(cfg)))\n",
    "    else:\n",
    "        cfg = None\n",
    "        print(\"-> not found model cfg...\")\n",
    "    print(\"=>  epoch {} Prec1: {}\".format(start_epoch, best_prec1))\n",
    "    return state_dict, opti_dict, start_epoch, best_prec1, cfg\n",
    "\n",
    "data_path = {\n",
    "    'root': r'D:\\Project\\Gitee\\network-slimming\\logs',\n",
    "    'at': [\n",
    "        'at_prune_densenet40_cifar10_percent_0.4',\n",
    "        'at_prune_densenet40_cifar10_percent_0.7',\n",
    "        'at_prune_densenet40_cifar100_percent_0.4',\n",
    "        'at_prune_densenet40_cifar100_percent_0.6',\n",
    "    ],\n",
    "    'bn': [\n",
    "        'bn_prune_densenet40_cifar10_percent_0.4',\n",
    "        'bn_prune_densenet40_cifar10_percent_0.7',\n",
    "        'bn_prune_densenet40_cifar100_percent_0.4',\n",
    "        'bn_prune_densenet40_cifar100_percent_0.6'\n",
    "    ],\n",
    "    'flie': 'model_best.pt',\n",
    "    'file2': 'model_best.pth.tar',\n",
    "    'file3': 'pruned.pt',\n",
    "}\n",
    "\n",
    "file_path = os.path.join(data_path['root'], data_path['at'][3], data_path['file3'])\n",
    "state_dict, opti_dict, start_epoch, best_prec1, cfg = resume_model(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = densenet(depth=40, dropRate=0, dataset='cifar100',\n",
    "                 growthRate=12, compressionRate=1, cfg=cfg, conv_cfg=None)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Params "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 thop\n",
    "    计算parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from thop import profile\n",
    "from thop import clever_format\n",
    "\n",
    "\n",
    "input = torch.randn(1, 3, 32, 32)\n",
    "flops, params = profile(model, inputs=(input, ))\n",
    "print(flops, params)\n",
    "flops, params = clever_format([flops, params], \"%.2f\")\n",
    "flops, params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 torchstat\n",
    "    计算flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchstat import stat\n",
    "\n",
    "stat(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3  ptflops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "with torch.cuda.device(0):\n",
    "    macs, params = get_model_complexity_info(model, (3, 32, 32), as_strings=True,\n",
    "                                           print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))\n",
    "macs, params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 torchsummary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (3, 32, 32), device='cpu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python37] *",
   "language": "python",
   "name": "conda-env-python37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
