{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. list 转成 array 实现减法\n",
    "两个list不能直接做减法，需要转成array，计算后，再转回list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 64- 35= 29',\n",
       " ' 64- 64=  0',\n",
       " '128-128=  0',\n",
       " '128-128=  0',\n",
       " '256-255=  1',\n",
       " '256-251=  5',\n",
       " '256-222= 34',\n",
       " '256-180= 76',\n",
       " '512-113=399',\n",
       " '512- 46=466',\n",
       " '512- 44=468',\n",
       " '512- 34=478',\n",
       " '512- 17=495',\n",
       " '512- 21=491',\n",
       " '512- 33=479',\n",
       " '512- 80=432']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "channel_origin = [64, 64, 128, 128, 256, 256, 256, 256, 512, 512, 512, 512, 512, 512, 512, 512]  # vgg19 model\n",
    "channel_prune = [35, 64, 128, 128, 255, 251, 222, 180, 113, 46, 44, 34, 17, 21, 33, 80]  # prune.txt\n",
    "\n",
    "channel_variation = np.array(channel_origin) - np.array(channel_prune)\n",
    "channel_variation = list(channel_variation)\n",
    "\n",
    "# print(len(channel_origin), len(channel_prune))\n",
    "labels = [\"{:>3d}-{:>3d}={:>3d}\".format(origin_item, channel_prune[i], channel_variation[i]) for i, origin_item in enumerate(channel_origin)]\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. np.reshape() 与 np.resize() 是不同的\n",
    "\n",
    "- reshape 只能改变形状，不能改变原始输入包含的元素个数\n",
    "- resize 可以改变尺寸,只是进行简单的裁剪和填充。如果要更加精确的使用插值，则该函数不能实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.32504546,  0.0767059 , -0.19079044, -0.86248992]), (4,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.random.randn(4)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.32504546],\n",
       "        [ 0.0767059 ],\n",
       "        [-0.19079044],\n",
       "        [-0.86248992]]),\n",
       " array([-1.32504546,  0.0767059 , -0.19079044, -0.86248992]),\n",
       " (4,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.reshape(4, 1)\n",
    "# y = np.reshape(4, 1)\n",
    "y, x,  x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.32504546,  0.0767059 ],\n",
       "        [-0.19079044, -0.86248992],\n",
       "        [-1.32504546,  0.0767059 ],\n",
       "        [-0.19079044, -0.86248992]]),\n",
       " (4, 2),\n",
       " array([-2.32504546, -0.9232941 , -1.19079044, -1.86248992]),\n",
       " (4,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.resize(x, (4, 2))\n",
    "z, z.shape, x - 1, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**size** 与 **shape** 是不一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.32504546]), (1,), 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = np.resize(z, (1,))\n",
    "o, o.shape, o.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.99293049]]),\n",
       " (1, 1),\n",
       " array(0.99293049),\n",
       " (),\n",
       " array([0.99293049]),\n",
       " (1,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = np.random.randn(1, 1)\n",
    "o = np.squeeze(m)\n",
    "n = np.resize(o, (1,))\n",
    "m, m.shape, o, o.shape, n, n.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. vars() 提供打印变量的所有参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'PyTorch Slimming CIFAR training',\n",
       " 'argument_default': None,\n",
       " 'prefix_chars': '-',\n",
       " 'conflict_handler': 'error',\n",
       " '_registries': {'action': {None: argparse._StoreAction,\n",
       "   'store': argparse._StoreAction,\n",
       "   'store_const': argparse._StoreConstAction,\n",
       "   'store_true': argparse._StoreTrueAction,\n",
       "   'store_false': argparse._StoreFalseAction,\n",
       "   'append': argparse._AppendAction,\n",
       "   'append_const': argparse._AppendConstAction,\n",
       "   'count': argparse._CountAction,\n",
       "   'help': argparse._HelpAction,\n",
       "   'version': argparse._VersionAction,\n",
       "   'parsers': argparse._SubParsersAction},\n",
       "  'type': {None: <function argparse.ArgumentParser.__init__.<locals>.identity(string)>}},\n",
       " '_actions': [_HelpAction(option_strings=['-h', '--help'], dest='help', nargs=0, const=None, default='==SUPPRESS==', type=None, choices=None, help='show this help message and exit', metavar=None),\n",
       "  _StoreAction(option_strings=['--dataset'], dest='dataset', nargs=None, const=None, default='cifar100', type=<class 'str'>, choices=None, help='training dataset (default: cifar100)', metavar=None),\n",
       "  _StoreTrueAction(option_strings=['--sparsity-regularization', '-sr'], dest='sr', nargs=0, const=True, default=False, type=None, choices=None, help='train with channel sparsity regularization', metavar=None),\n",
       "  _StoreAction(option_strings=['--s'], dest='s', nargs=None, const=None, default=0.0001, type=<class 'float'>, choices=None, help='scale sparse rate (default: 0.0001)', metavar=None)],\n",
       " '_option_string_actions': {'-h': _HelpAction(option_strings=['-h', '--help'], dest='help', nargs=0, const=None, default='==SUPPRESS==', type=None, choices=None, help='show this help message and exit', metavar=None),\n",
       "  '--help': _HelpAction(option_strings=['-h', '--help'], dest='help', nargs=0, const=None, default='==SUPPRESS==', type=None, choices=None, help='show this help message and exit', metavar=None),\n",
       "  '--dataset': _StoreAction(option_strings=['--dataset'], dest='dataset', nargs=None, const=None, default='cifar100', type=<class 'str'>, choices=None, help='training dataset (default: cifar100)', metavar=None),\n",
       "  '--sparsity-regularization': _StoreTrueAction(option_strings=['--sparsity-regularization', '-sr'], dest='sr', nargs=0, const=True, default=False, type=None, choices=None, help='train with channel sparsity regularization', metavar=None),\n",
       "  '-sr': _StoreTrueAction(option_strings=['--sparsity-regularization', '-sr'], dest='sr', nargs=0, const=True, default=False, type=None, choices=None, help='train with channel sparsity regularization', metavar=None),\n",
       "  '--s': _StoreAction(option_strings=['--s'], dest='s', nargs=None, const=None, default=0.0001, type=<class 'float'>, choices=None, help='scale sparse rate (default: 0.0001)', metavar=None)},\n",
       " '_action_groups': [<argparse._ArgumentGroup at 0x22860a95a08>,\n",
       "  <argparse._ArgumentGroup at 0x22860a95988>],\n",
       " '_mutually_exclusive_groups': [],\n",
       " '_defaults': {},\n",
       " '_negative_number_matcher': re.compile(r'^-\\d+$|^-\\d*\\.\\d+$', re.UNICODE),\n",
       " '_has_negative_number_optionals': [],\n",
       " 'prog': 'ipykernel_launcher.py',\n",
       " 'usage': None,\n",
       " 'epilog': None,\n",
       " 'formatter_class': argparse.HelpFormatter,\n",
       " 'fromfile_prefix_chars': None,\n",
       " 'add_help': True,\n",
       " 'allow_abbrev': True,\n",
       " '_positionals': <argparse._ArgumentGroup at 0x22860a95a08>,\n",
       " '_optionals': <argparse._ArgumentGroup at 0x22860a95988>,\n",
       " '_subparsers': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "# Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch Slimming CIFAR training')\n",
    "parser.add_argument('--dataset', type=str, default='cifar100',\n",
    "                    help='training dataset (default: cifar100)')\n",
    "parser.add_argument('--sparsity-regularization', '-sr', dest='sr', action='store_true',\n",
    "                    help='train with channel sparsity regularization')\n",
    "parser.add_argument('--s', type=float, default=0.0001,\n",
    "                    help='scale sparse rate (default: 0.0001)')\n",
    "\n",
    "vars(parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. gt() 大于操作，返回值为 True or False\n",
    "\n",
    "- gt (greater than) 大于\n",
    "- lt (less than) 小于\n",
    "- eq (equal) 等于\n",
    "- ge (greater and equal) 大于等于\n",
    "- le (less and equal) 小于等于\n",
    "\n",
    "布尔类型转换为浮点型： result.float() 返回 [1.0, 0.0, ..., 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.rand(5)\n",
    "y, i = torch.sort(x)\n",
    "print(\"x\", x, \"\\ny\", y, \"\\ni\", i)\n",
    "\n",
    "mask = i.gt(2)\n",
    "mask_float = mask.float()\n",
    "mask, mask_float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. np.argwhere(x > 0)  返回x中大于0的数组元组的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = [1, 2, 3, -1, -2]\n",
    "x = torch.tensor(x)\n",
    "y = np.argwhere(x.data.cpu().numpy() > 0)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. squeeze() 与 unsqueeze()\n",
    "\n",
    "- squeeze() 压缩一个维度，仅当当前维度为1，否则不做修改\n",
    "- unsqueeze(num) 增加一个维度，num可以为负数，表示在倒数第num个维度增加一个维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1, 2]),\n",
       " torch.Size([3, 1, 2]),\n",
       " torch.Size([3, 2]),\n",
       " torch.Size([3, 1, 2]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(3, 1, 2)\n",
    "y = x.squeeze(0)  # not modify\n",
    "z = x.squeeze(1)  # modified\n",
    "w = z.unsqueeze(-2)\n",
    "x.shape, y.shape, z.shape, w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. nn.ReLU() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.3862,  0.3717,  1.3680,  0.5028,  0.0278]),\n",
       " tensor([0.0000, 0.3717, 1.3680, 0.5028, 0.0278]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "m = torch.nn.ReLU()\n",
    "x = torch.randn(5)\n",
    "y = m(x)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linalg.norm() 与 nn.functional.normalize() 的区别\n",
    "\n",
    "- `torch.norm` 已废弃，不建议使用\n",
    "- [linalg.norm](https://pytorch.org/docs/stable/linalg.html?highlight=norm#torch.linalg.norm) 计算矩阵二范式，是一个数。计算二维矩阵的二范式矩阵：\n",
    "    - 先计算整个矩阵的二范数\n",
    "    - 用矩阵除以这个二范数\n",
    "- [nn.functional.normalize](https://pytorch.org/docs/stable/nn.functional.html?highlight=normalize#torch.nn.functional.normalize) 计算矩阵或Tensor某个`dim`维度的二范式后的矩阵，是一个矩阵。\n",
    "    - <u>不能用于二维矩阵计算，仅用于沿某个维度的二范式计算。</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P范数的一般形式\n",
    "若x=[x<sub>1</sub> + x<sub>2</sub> + ... + x<sub>n</sub>]，则 ||x||<sub>p</sub> = (|x<sub>1</sub>|<sup>p</sup> + |x<sub>2</sub> |<sup>p</sup>+ ... + |x<sub>n</sub>|<sup>p</sup>)^(1/p)\n",
    "\n",
    "当p取0, 1, ∞时，有以下三种情形：\n",
    "- p=1，一范式：||x||<sub>1</sub> = ( |x<sub>1</sub>| + |x<sub>2</sub> | + ... + |x<sub>n</sub>| )\n",
    "- p=2，二范式：||x||<sub>2</sub> = ( |x<sub>1</sub>|<sup>2</sup> + |x<sub>2</sub> |<sup>2</sup>+ ... + |x<sub>n</sub>|<sup>2</sup> )^(1/2)\n",
    "- p=∞，三范式：||x||<sub>∞</sub> = max( |x<sub>1</sub>| + |x<sub>2</sub> | + ... + |x<sub>n</sub>| )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linalg.norm() 计算矩阵的二范式，是一个数\n",
    "\n",
    "torch.linalg.norm(`input`, `ord`=None, `dim`=None, `keepdim`=False, *, `out`=None, `dtype`=None) → Tensor\n",
    "- `input`: The input tensor. If dim is None, x must be 1-D or 2-D, unless ord is None. <u>*If both dim and ord are None, the 2-norm of the input flattened to 1-D will be returned.*</u> Its data type must be either a floating point or complex type. For complex inputs, the norm is calculated on of the absolute values of each element. If the input is complex and neither dtype nor out is specified, the result’s data type will be the corresponding floating point type (e.g. float if input is complexfloat).\n",
    "- `ord`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.ones(2, 2)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### linalg.norm() 返回二维矩阵的二范式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.),\n",
       " tensor([[0.5000, 0.5000],\n",
       "         [0.5000, 0.5000]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_data = torch.linalg.norm(data)  # torch.linalg.norm(data, p=2, ord=None)\n",
    "result1 = data / norm_data\n",
    "norm_data, result1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.functional.normalize(input, p, dim, eps) 返回沿某个`dim`维度的二范式矩阵\n",
    "\n",
    "normalize(`input`: Tensor, `p`: float = 2, `dim`: int = 1, `eps`: float = 1e-12, `out`: Optional[Tensor] = None) -> Tensor\n",
    "- `input`: input tensor of any shape\n",
    "- `p` (float): the exponent value in the norm formulation. Default: 2\n",
    "- `dim` (int): the dimension to reduce. Default: 1\n",
    "- `eps` (float): small value to avoid division by zero. Default: 1e-12\n",
    "- `out` (Tensor, optional): the output tensor. If :attr:`out` is used, this operation won't be differentiable.\n",
    "\n",
    "<u>但不能用于二维矩阵计算，仅用于沿某个维度的二范式计算</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3 = torch.ones(1, 4)\n",
    "data3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dim=1（默认值），沿着第二个维度计算二范式矩阵\n",
    "- norm = sqrt(1^2 + 1^2 + 1^2 + 1^2) = 2\n",
    "- result = data / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.5000, 0.5000, 0.5000]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3 = fn.normalize(data3, p=2, dim=1)\n",
    "result3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dim=0, 沿着第一个维度上计算二范式矩阵\n",
    "- norm0 = sqrt(1^2) = 1\n",
    "- norm1 = sqrt(1^2) = 1\n",
    "- norm2 = sqrt(1^2) = 1\n",
    "- norm3 = sqrt(1^2) = 1\n",
    "- result = data / [norm0, norm1, norm2, norm3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result4 = fn.normalize(data3, p=2, dim=0)  # 第一个维度\n",
    "result4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python37] *",
   "language": "python",
   "name": "conda-env-python37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
