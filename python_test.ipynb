{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda\\envs\\python37\\lib\\site-packages\\torchtext\\data\\example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "D:\\Program\\Anaconda\\envs\\python37\\lib\\site-packages\\torchtext\\data\\iterator.py:48: UserWarning: BPTTIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans <unk> of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the\n",
      "originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans <unk> of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the organization\n",
      "1\n",
      "organization of society it has also been taken up as a positive label by self defined anarchists the word anarchism is derived from the greek without archons ruler chief king anarchism as a political philosophy is the belief that rulers are unnecessary and should be abolished although there are differing\n",
      "of society it has also been taken up as a positive label by self defined anarchists the word anarchism is derived from the greek without archons ruler chief king anarchism as a political philosophy is the belief that rulers are unnecessary and should be abolished although there are differing interpretations\n",
      "2\n",
      "interpretations of what this means anarchism also refers to related social movements that advocate the elimination of authoritarian institutions particularly the state the word anarchy as most anarchists use it does not imply chaos nihilism or <unk> but rather a harmonious anti authoritarian society in place of what are regarded\n",
      "of what this means anarchism also refers to related social movements that advocate the elimination of authoritarian institutions particularly the state the word anarchy as most anarchists use it does not imply chaos nihilism or <unk> but rather a harmonious anti authoritarian society in place of what are regarded as\n",
      "3\n",
      "as authoritarian political structures and coercive economic institutions anarchists advocate social relations based upon voluntary association of autonomous individuals mutual aid and self governance while anarchism is most easily defined by what it is against anarchists also offer positive visions of what they believe to be a truly free society\n",
      "authoritarian political structures and coercive economic institutions anarchists advocate social relations based upon voluntary association of autonomous individuals mutual aid and self governance while anarchism is most easily defined by what it is against anarchists also offer positive visions of what they believe to be a truly free society however\n",
      "4\n",
      "however ideas about how an anarchist society might work vary considerably especially with respect to economics there is also disagreement about how a free society might be brought about origins and predecessors kropotkin and others argue that before recorded history human society was organized on anarchist principles most anthropologists follow\n",
      "ideas about how an anarchist society might work vary considerably especially with respect to economics there is also disagreement about how a free society might be brought about origins and predecessors kropotkin and others argue that before recorded history human society was organized on anarchist principles most anthropologists follow kropotkin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda\\envs\\python37\\lib\\site-packages\\torchtext\\data\\batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "from torchtext.vocab import Vectors\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "\n",
    "\n",
    "# 为了保证实验结果能够复现，固定随机数\n",
    "SEED = 53113\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if USE_CUDA:\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EMBEDDING_SIZE = 100\n",
    "MAX_VOCAB_SIZE = 50000\n",
    "\n",
    "\n",
    "TEXT = torchtext.data.Field(lower=True)  # 输入的内容全部小写\n",
    "train, val, test = torchtext.datasets.LanguageModelingDataset.splits(\n",
    "    path=\".\", train=\"text8.train.txt\", validation=\"text8.dev.txt\",\n",
    "    test=\"text8.test.txt\", text_field=TEXT\n",
    ")\n",
    "\n",
    "\n",
    "TEXT.build_vocab(train, max_size=MAX_VOCAB_SIZE)    # 取50000个单词\n",
    "# TEXT.vocab.itos[0:10] # 其实有50002个单词，包含这两个： '<unk>'表示单词表以外的词， '<pad>'表示补全长度\n",
    "# TEXT.vocab.stoi['<unk>']\n",
    "\n",
    "\n",
    "# 梯度往回传的长度\n",
    "train_iter, val_iter, test_iter = torchtext.data.BPTTIterator.splits(\n",
    "    (train, val, test), batch_size=BATCH_SIZE, device=device,\n",
    "    bptt_len=50, repeat=False, shuffle=True\n",
    ")\n",
    "it = iter(train_iter)  # 拿到一个 iter\n",
    "for i in range(5):\n",
    "    batch = next(it)  # 一个batch\n",
    "    print(i)\n",
    "    print(\" \".join(TEXT.vocab.itos[i] for i in batch.text[:, 0].data.cpu()))\n",
    "    print(\" \".join(TEXT.vocab.itos[i] for i in batch.target[:, 0].data.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'PyTorch Slimming CIFAR training',\n",
       " 'argument_default': None,\n",
       " 'prefix_chars': '-',\n",
       " 'conflict_handler': 'error',\n",
       " '_registries': {'action': {None: argparse._StoreAction,\n",
       "   'store': argparse._StoreAction,\n",
       "   'store_const': argparse._StoreConstAction,\n",
       "   'store_true': argparse._StoreTrueAction,\n",
       "   'store_false': argparse._StoreFalseAction,\n",
       "   'append': argparse._AppendAction,\n",
       "   'append_const': argparse._AppendConstAction,\n",
       "   'count': argparse._CountAction,\n",
       "   'help': argparse._HelpAction,\n",
       "   'version': argparse._VersionAction,\n",
       "   'parsers': argparse._SubParsersAction},\n",
       "  'type': {None: <function argparse.ArgumentParser.__init__.<locals>.identity(string)>}},\n",
       " '_actions': [_HelpAction(option_strings=['-h', '--help'], dest='help', nargs=0, const=None, default='==SUPPRESS==', type=None, choices=None, help='show this help message and exit', metavar=None),\n",
       "  _StoreAction(option_strings=['--dataset'], dest='dataset', nargs=None, const=None, default='cifar100', type=<class 'str'>, choices=None, help='training dataset (default: cifar100)', metavar=None),\n",
       "  _StoreTrueAction(option_strings=['--sparsity-regularization', '-sr'], dest='sr', nargs=0, const=True, default=False, type=None, choices=None, help='train with channel sparsity regularization', metavar=None),\n",
       "  _StoreAction(option_strings=['--s'], dest='s', nargs=None, const=None, default=0.0001, type=<class 'float'>, choices=None, help='scale sparse rate (default: 0.0001)', metavar=None),\n",
       "  _StoreAction(option_strings=['--refine'], dest='refine', nargs=None, const=None, default='', type=<class 'str'>, choices=None, help='path to the pruned model to be fine tuned', metavar='PATH'),\n",
       "  _StoreAction(option_strings=['--batch-size'], dest='batch_size', nargs=None, const=None, default=64, type=<class 'int'>, choices=None, help='input batch size for training (default: 64)', metavar='N'),\n",
       "  _StoreAction(option_strings=['--test-batch-size'], dest='test_batch_size', nargs=None, const=None, default=256, type=<class 'int'>, choices=None, help='input batch size for testing (default: 256)', metavar='N'),\n",
       "  _StoreAction(option_strings=['--epochs'], dest='epochs', nargs=None, const=None, default=160, type=<class 'int'>, choices=None, help='number of epochs to train (default: 160)', metavar='N'),\n",
       "  _StoreAction(option_strings=['--start-epoch'], dest='start_epoch', nargs=None, const=None, default=0, type=<class 'int'>, choices=None, help='manual epoch number (useful on restarts)', metavar='N'),\n",
       "  _StoreAction(option_strings=['--lr'], dest='lr', nargs=None, const=None, default=0.1, type=<class 'float'>, choices=None, help='learning rate (default: 0.1)', metavar='LR'),\n",
       "  _StoreAction(option_strings=['--momentum'], dest='momentum', nargs=None, const=None, default=0.9, type=<class 'float'>, choices=None, help='SGD momentum (default: 0.9)', metavar='M'),\n",
       "  _StoreAction(option_strings=['--weight-decay', '--wd'], dest='weight_decay', nargs=None, const=None, default=0.0001, type=<class 'float'>, choices=None, help='weight decay (default: 1e-4)', metavar='W'),\n",
       "  _StoreAction(option_strings=['--resume'], dest='resume', nargs=None, const=None, default='', type=<class 'str'>, choices=None, help='path to latest checkpoint (default: none)', metavar='PATH'),\n",
       "  _StoreTrueAction(option_strings=['--no-cuda'], dest='no_cuda', nargs=0, const=True, default=False, type=None, choices=None, help='disables CUDA training', metavar=None),\n",
       "  _StoreAction(option_strings=['--seed'], dest='seed', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help='random seed (default: 1)', metavar='S'),\n",
       "  _StoreAction(option_strings=['--log-interval'], dest='log_interval', nargs=None, const=None, default=100, type=<class 'int'>, choices=None, help='how many batches to wait before logging training status', metavar='N'),\n",
       "  _StoreAction(option_strings=['--save'], dest='save', nargs=None, const=None, default='./logs', type=<class 'str'>, choices=None, help='path to save prune model (default: current directory)', metavar='PATH'),\n",
       "  _StoreAction(option_strings=['--arch'], dest='arch', nargs=None, const=None, default='vgg', type=<class 'str'>, choices=None, help='architecture to use', metavar=None),\n",
       "  _StoreAction(option_strings=['--depth'], dest='depth', nargs=None, const=None, default=19, type=<class 'int'>, choices=None, help='depth of the neural network', metavar=None)],\n",
       " '_option_string_actions': {'-h': _HelpAction(option_strings=['-h', '--help'], dest='help', nargs=0, const=None, default='==SUPPRESS==', type=None, choices=None, help='show this help message and exit', metavar=None),\n",
       "  '--help': _HelpAction(option_strings=['-h', '--help'], dest='help', nargs=0, const=None, default='==SUPPRESS==', type=None, choices=None, help='show this help message and exit', metavar=None),\n",
       "  '--dataset': _StoreAction(option_strings=['--dataset'], dest='dataset', nargs=None, const=None, default='cifar100', type=<class 'str'>, choices=None, help='training dataset (default: cifar100)', metavar=None),\n",
       "  '--sparsity-regularization': _StoreTrueAction(option_strings=['--sparsity-regularization', '-sr'], dest='sr', nargs=0, const=True, default=False, type=None, choices=None, help='train with channel sparsity regularization', metavar=None),\n",
       "  '-sr': _StoreTrueAction(option_strings=['--sparsity-regularization', '-sr'], dest='sr', nargs=0, const=True, default=False, type=None, choices=None, help='train with channel sparsity regularization', metavar=None),\n",
       "  '--s': _StoreAction(option_strings=['--s'], dest='s', nargs=None, const=None, default=0.0001, type=<class 'float'>, choices=None, help='scale sparse rate (default: 0.0001)', metavar=None),\n",
       "  '--refine': _StoreAction(option_strings=['--refine'], dest='refine', nargs=None, const=None, default='', type=<class 'str'>, choices=None, help='path to the pruned model to be fine tuned', metavar='PATH'),\n",
       "  '--batch-size': _StoreAction(option_strings=['--batch-size'], dest='batch_size', nargs=None, const=None, default=64, type=<class 'int'>, choices=None, help='input batch size for training (default: 64)', metavar='N'),\n",
       "  '--test-batch-size': _StoreAction(option_strings=['--test-batch-size'], dest='test_batch_size', nargs=None, const=None, default=256, type=<class 'int'>, choices=None, help='input batch size for testing (default: 256)', metavar='N'),\n",
       "  '--epochs': _StoreAction(option_strings=['--epochs'], dest='epochs', nargs=None, const=None, default=160, type=<class 'int'>, choices=None, help='number of epochs to train (default: 160)', metavar='N'),\n",
       "  '--start-epoch': _StoreAction(option_strings=['--start-epoch'], dest='start_epoch', nargs=None, const=None, default=0, type=<class 'int'>, choices=None, help='manual epoch number (useful on restarts)', metavar='N'),\n",
       "  '--lr': _StoreAction(option_strings=['--lr'], dest='lr', nargs=None, const=None, default=0.1, type=<class 'float'>, choices=None, help='learning rate (default: 0.1)', metavar='LR'),\n",
       "  '--momentum': _StoreAction(option_strings=['--momentum'], dest='momentum', nargs=None, const=None, default=0.9, type=<class 'float'>, choices=None, help='SGD momentum (default: 0.9)', metavar='M'),\n",
       "  '--weight-decay': _StoreAction(option_strings=['--weight-decay', '--wd'], dest='weight_decay', nargs=None, const=None, default=0.0001, type=<class 'float'>, choices=None, help='weight decay (default: 1e-4)', metavar='W'),\n",
       "  '--wd': _StoreAction(option_strings=['--weight-decay', '--wd'], dest='weight_decay', nargs=None, const=None, default=0.0001, type=<class 'float'>, choices=None, help='weight decay (default: 1e-4)', metavar='W'),\n",
       "  '--resume': _StoreAction(option_strings=['--resume'], dest='resume', nargs=None, const=None, default='', type=<class 'str'>, choices=None, help='path to latest checkpoint (default: none)', metavar='PATH'),\n",
       "  '--no-cuda': _StoreTrueAction(option_strings=['--no-cuda'], dest='no_cuda', nargs=0, const=True, default=False, type=None, choices=None, help='disables CUDA training', metavar=None),\n",
       "  '--seed': _StoreAction(option_strings=['--seed'], dest='seed', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help='random seed (default: 1)', metavar='S'),\n",
       "  '--log-interval': _StoreAction(option_strings=['--log-interval'], dest='log_interval', nargs=None, const=None, default=100, type=<class 'int'>, choices=None, help='how many batches to wait before logging training status', metavar='N'),\n",
       "  '--save': _StoreAction(option_strings=['--save'], dest='save', nargs=None, const=None, default='./logs', type=<class 'str'>, choices=None, help='path to save prune model (default: current directory)', metavar='PATH'),\n",
       "  '--arch': _StoreAction(option_strings=['--arch'], dest='arch', nargs=None, const=None, default='vgg', type=<class 'str'>, choices=None, help='architecture to use', metavar=None),\n",
       "  '--depth': _StoreAction(option_strings=['--depth'], dest='depth', nargs=None, const=None, default=19, type=<class 'int'>, choices=None, help='depth of the neural network', metavar=None)},\n",
       " '_action_groups': [<argparse._ArgumentGroup at 0x1e3adf42348>,\n",
       "  <argparse._ArgumentGroup at 0x1e3adf42308>],\n",
       " '_mutually_exclusive_groups': [],\n",
       " '_defaults': {},\n",
       " '_negative_number_matcher': re.compile(r'^-\\d+$|^-\\d*\\.\\d+$', re.UNICODE),\n",
       " '_has_negative_number_optionals': [],\n",
       " 'prog': 'ipykernel_launcher.py',\n",
       " 'usage': None,\n",
       " 'epilog': None,\n",
       " 'formatter_class': argparse.HelpFormatter,\n",
       " 'fromfile_prefix_chars': None,\n",
       " 'add_help': True,\n",
       " 'allow_abbrev': True,\n",
       " '_positionals': <argparse._ArgumentGroup at 0x1e3adf42348>,\n",
       " '_optionals': <argparse._ArgumentGroup at 0x1e3adf42308>,\n",
       " '_subparsers': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "# Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch Slimming CIFAR training')\n",
    "parser.add_argument('--dataset', type=str, default='cifar100',\n",
    "                    help='training dataset (default: cifar100)')\n",
    "parser.add_argument('--sparsity-regularization', '-sr', dest='sr', action='store_true',\n",
    "                    help='train with channel sparsity regularization')\n",
    "parser.add_argument('--s', type=float, default=0.0001,\n",
    "                    help='scale sparse rate (default: 0.0001)')\n",
    "parser.add_argument('--refine', default='', type=str, metavar='PATH',\n",
    "                    help='path to the pruned model to be fine tuned')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=256, metavar='N',\n",
    "                    help='input batch size for testing (default: 256)')\n",
    "parser.add_argument('--epochs', type=int, default=160, metavar='N',\n",
    "                    help='number of epochs to train (default: 160)')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('--lr', type=float, default=0.1, metavar='LR',\n",
    "                    help='learning rate (default: 0.1)')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n",
    "                    help='SGD momentum (default: 0.9)')\n",
    "parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)')\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=100, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--save', default='./logs', type=str, metavar='PATH',\n",
    "                    help='path to save prune model (default: current directory)')\n",
    "parser.add_argument('--arch', default='vgg', type=str, \n",
    "                    help='architecture to use')\n",
    "parser.add_argument('--depth', default=19, type=int,\n",
    "                    help='depth of the neural network')\n",
    "\n",
    "vars(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([0.4631, 0.1301, 0.3086, 0.1923, 0.8349]) \n",
      "y tensor([0.1301, 0.1923, 0.3086, 0.4631, 0.8349]) \n",
      "i tensor([1, 3, 2, 0, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([False,  True, False, False,  True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.rand(5)\n",
    "\n",
    "y, i = torch.sort(x)\n",
    "print(\"x\", x, \"\\ny\", y, \"\\ni\", i)\n",
    "\n",
    "\n",
    "i.gt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = [1, 2, 3, -1, -2]\n",
    "x = torch.tensor(x)\n",
    "y = np.argwhere(x.data.cpu().numpy() > 0)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "vgg19 = models.vgg19(pretrained=True)\n",
    "vgg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-5.3474e-02, -4.9257e-02, -6.7942e-02],\n",
       "          [ 1.5314e-02,  4.5068e-02,  2.1444e-03],\n",
       "          [ 3.6226e-02,  1.9999e-02,  1.9864e-02]],\n",
       "\n",
       "         [[ 1.7015e-02,  5.5403e-02, -6.2293e-03],\n",
       "          [ 1.4165e-01,  2.2705e-01,  1.3758e-01],\n",
       "          [ 1.2000e-01,  2.0030e-01,  9.2114e-02]],\n",
       "\n",
       "         [[-4.4885e-02,  1.2680e-02, -1.4497e-02],\n",
       "          [ 5.9742e-02,  1.3955e-01,  5.4102e-02],\n",
       "          [-9.6141e-04,  5.8304e-02, -2.9663e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 2.6072e-01, -3.0489e-01, -5.0152e-01],\n",
       "          [ 4.1376e-01, -2.0831e-01, -4.9086e-01],\n",
       "          [ 5.8770e-01,  4.2851e-01, -1.3850e-01]],\n",
       "\n",
       "         [[ 2.8746e-01, -3.3338e-01, -4.5564e-01],\n",
       "          [ 3.7836e-01, -2.9144e-01, -4.9720e-01],\n",
       "          [ 5.4778e-01,  4.8983e-01, -1.7166e-01]],\n",
       "\n",
       "         [[ 6.7260e-02, -9.5386e-02, -3.8037e-02],\n",
       "          [ 6.1955e-02, -1.3125e-01, -1.0691e-01],\n",
       "          [ 4.8107e-02,  2.2999e-01, -3.0578e-02]]],\n",
       "\n",
       "\n",
       "        [[[-3.2457e-02,  1.6281e-01,  5.9687e-02],\n",
       "          [ 1.3960e-01,  3.7732e-01,  2.3204e-01],\n",
       "          [ 3.0062e-02,  1.9476e-01,  8.5276e-02]],\n",
       "\n",
       "         [[-9.5406e-02,  9.6072e-02, -2.5564e-02],\n",
       "          [ 2.3299e-02,  2.8450e-01,  9.4697e-02],\n",
       "          [-1.4335e-01, -6.8587e-05, -1.0202e-01]],\n",
       "\n",
       "         [[-1.2480e-01,  5.2403e-02, -2.6687e-02],\n",
       "          [-4.1414e-02,  1.7935e-01,  4.9905e-02],\n",
       "          [-1.1839e-01, -2.0942e-02, -1.0207e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-5.2884e-02, -1.1182e-01, -2.2377e-02],\n",
       "          [-1.8517e-01, -2.6329e-01, -4.5673e-02],\n",
       "          [-1.2462e-01, -1.5776e-01, -2.5907e-02]],\n",
       "\n",
       "         [[-6.8542e-02, -1.0528e-01, -5.6703e-02],\n",
       "          [-1.4858e-01, -1.7634e-01,  3.1325e-02],\n",
       "          [-9.2168e-02, -4.9276e-02,  3.2291e-02]],\n",
       "\n",
       "         [[ 1.2216e-01,  2.0694e-01,  1.8405e-01],\n",
       "          [ 1.5762e-01,  2.3937e-01,  2.8790e-01],\n",
       "          [ 8.4974e-02,  1.7520e-01,  1.5766e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.5902e-02,  3.8224e-01,  2.9388e-01],\n",
       "          [-4.7560e-01, -3.6006e-01,  2.3282e-01],\n",
       "          [-2.2283e-01,  8.3313e-04,  1.5329e-01]],\n",
       "\n",
       "         [[ 1.7674e-01,  3.8770e-01,  2.6036e-02],\n",
       "          [-3.9036e-01, -5.0041e-01,  1.7150e-03],\n",
       "          [ 6.1660e-02,  1.4792e-01,  5.1035e-02]],\n",
       "\n",
       "         [[ 1.2967e-01,  7.5381e-02, -3.8851e-01],\n",
       "          [ 5.0931e-02, -1.9381e-01, -1.7501e-01],\n",
       "          [ 3.4483e-01,  2.1557e-01, -8.3478e-02]]],\n",
       "\n",
       "\n",
       "        [[[-8.1056e-01, -7.4319e-01, -7.7885e-01],\n",
       "          [-1.6934e-01,  3.4232e-01, -7.0197e-02],\n",
       "          [ 5.2494e-01,  9.5989e-01,  7.6209e-01]],\n",
       "\n",
       "         [[ 7.9164e-02,  2.4559e-01, -1.5317e-01],\n",
       "          [-7.0860e-02,  4.4652e-01, -3.8074e-01],\n",
       "          [-1.5309e-01,  1.2427e-01, -1.1070e-01]],\n",
       "\n",
       "         [[ 5.2029e-01,  7.5736e-01,  6.2371e-01],\n",
       "          [-1.0733e-01,  1.8762e-01, -1.2183e-01],\n",
       "          [-6.6407e-01, -6.4891e-01, -5.5356e-01]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg19.features[0].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 3, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg19.features[0].weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 512, 3, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg19.features[32].weight.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## list减法\n",
    "\n",
    "两个list不能直接做减法，需要转成array，计算后，再转回list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 64- 35= 29',\n",
       " ' 64- 64=  0',\n",
       " '128-128=  0',\n",
       " '128-128=  0',\n",
       " '256-255=  1',\n",
       " '256-251=  5',\n",
       " '256-222= 34',\n",
       " '256-180= 76',\n",
       " '512-113=399',\n",
       " '512- 46=466',\n",
       " '512- 44=468',\n",
       " '512- 34=478',\n",
       " '512- 17=495',\n",
       " '512- 21=491',\n",
       " '512- 33=479',\n",
       " '512- 80=432']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "channel_origin = [64, 64, 128, 128, 256, 256, 256, 256, 512, 512, 512, 512, 512, 512, 512, 512]  # vgg19 model\n",
    "channel_prune = [35, 64, 128, 128, 255, 251, 222, 180, 113, 46, 44, 34, 17, 21, 33, 80]  # prune.txt\n",
    "\n",
    "channel_variation = np.array(channel_origin) - np.array(channel_prune)\n",
    "channel_variation = list(channel_variation)\n",
    "\n",
    "# print(len(channel_origin), len(channel_prune))\n",
    "labels = [\"{:>3d}-{:>3d}={:>3d}\".format(origin_item, channel_prune[i], channel_variation[i]) for i, origin_item in enumerate(channel_origin)]\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.reshape()与np.resize()\n",
    "\n",
    "- reshape 只能改变形状，不能改变原始输入包含的元素个数\n",
    "- resize 可以改变尺寸,只是进行简单的裁剪和填充。如果要更加精确的使用插值，则该函数不能实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-2.06767764, -1.1926219 ,  0.07554309, -0.0070737 ]), (4,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.random.randn(4)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-2.06767764],\n",
       "        [-1.1926219 ],\n",
       "        [ 0.07554309],\n",
       "        [-0.0070737 ]]),\n",
       " array([-2.06767764, -1.1926219 ,  0.07554309, -0.0070737 ]),\n",
       " (4,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.reshape(x, (4, 1))\n",
    "# y = np.reshape(4, 1)\n",
    "y, x,  x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-2.06767764, -1.1926219 ],\n",
       "        [ 0.07554309, -0.0070737 ],\n",
       "        [-2.06767764, -1.1926219 ],\n",
       "        [ 0.07554309, -0.0070737 ]]),\n",
       " (4, 2),\n",
       " array([[-3.06767764, -2.1926219 ],\n",
       "        [-0.92445691, -1.0070737 ]]),\n",
       " (2, 2))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.resize(x, (4, 2))\n",
    "z, z.shape, x - 1, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-2.06767764]), (1,), 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = np.resize(z, (1,))\n",
    "o, o.shape, o.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.7372842]]),\n",
       " (1, 1),\n",
       " array(-0.7372842),\n",
       " (),\n",
       " array([-0.7372842]),\n",
       " (1,))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = np.random.randn(1, 1)\n",
    "o = np.squeeze(m)\n",
    "n = np.resize(o, (1,))\n",
    "m, m.shape, o, o.shape, n, n.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataloader遍历"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "            datasets.CIFAR10('./data.cifar10', train=False, download=True, transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n",
    "            batch_size=256, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 3, 32, 32]), torch.Size([256]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx, data = next(enumerate(test_loader))\n",
    "data[0].shape, data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\" to C:\\Users\\jdema/.cache\\torch\\hub\\checkpoints\\vgg19_bn-c79401a0.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003bc71efb1f4d0b8d001a9202c6f49c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=574769405.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (38): ReLU(inplace=True)\n",
       "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (45): ReLU(inplace=True)\n",
       "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (48): ReLU(inplace=True)\n",
       "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (51): ReLU(inplace=True)\n",
       "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "vgg19 = models.vgg19_bn(pretrained=True)\n",
    "vgg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = data[0][0].clone().unsqueeze(0)\n",
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-8.5106e-08, -7.2914e-08,  7.8384e-10,  ...,  1.6261e-06,\n",
       "             2.7526e-06,  2.5523e-06],\n",
       "           [-1.3694e-07, -1.5476e-07, -2.0210e-07,  ...,  2.7468e-06,\n",
       "             4.3231e-06,  3.9384e-06],\n",
       "           [-3.3755e-07, -4.3320e-07, -5.1764e-07,  ...,  2.9127e-06,\n",
       "             4.3238e-06,  3.9556e-06],\n",
       "           ...,\n",
       "           [-1.5394e-06, -2.5490e-06, -2.5003e-06,  ..., -1.9278e-06,\n",
       "            -1.9479e-06, -1.6941e-06],\n",
       "           [-1.5366e-06, -2.6200e-06, -2.6268e-06,  ..., -1.8583e-06,\n",
       "            -1.9974e-06, -1.7430e-06],\n",
       "           [-1.2952e-06, -2.2182e-06, -2.2789e-06,  ..., -1.3832e-06,\n",
       "            -1.6083e-06, -1.3835e-06]],\n",
       " \n",
       "          [[ 8.8070e-08,  1.5682e-07,  1.6829e-07,  ...,  1.2236e-06,\n",
       "             1.8164e-06,  1.5073e-06],\n",
       "           [-8.1696e-08, -1.6041e-07, -2.2403e-07,  ...,  1.3481e-06,\n",
       "             1.8669e-06,  1.5077e-06],\n",
       "           [-4.0767e-07, -5.6811e-07, -4.2556e-07,  ...,  1.1668e-06,\n",
       "             1.8114e-06,  1.5591e-06],\n",
       "           ...,\n",
       "           [-7.5867e-07, -1.1056e-06, -1.1009e-06,  ..., -7.6572e-07,\n",
       "            -7.8026e-07, -5.9673e-07],\n",
       "           [-7.7240e-07, -1.1324e-06, -1.1667e-06,  ..., -6.6568e-07,\n",
       "            -7.7889e-07, -6.1413e-07],\n",
       "           [-3.8521e-07, -5.1201e-07, -5.3664e-07,  ..., -1.7405e-07,\n",
       "            -2.5374e-07, -1.9104e-07]],\n",
       " \n",
       "          [[ 8.9837e-01,  6.8866e-01,  7.4941e-01,  ...,  6.4296e-01,\n",
       "             1.1419e+00,  1.6193e+00],\n",
       "           [ 7.6556e-01,  4.5383e-01,  3.9320e-01,  ...,  1.7457e+00,\n",
       "             2.0901e+00,  2.3079e+00],\n",
       "           [ 4.5850e-01,  4.8153e-01,  4.5840e-01,  ...,  1.7628e+00,\n",
       "             2.1731e+00,  2.3781e+00],\n",
       "           ...,\n",
       "           [-1.0824e+00, -1.2636e+00, -1.2230e+00,  ..., -1.0435e+00,\n",
       "            -1.0661e+00, -9.4187e-01],\n",
       "           [-8.2777e-01, -9.1631e-01, -9.8212e-01,  ..., -1.1311e+00,\n",
       "            -1.1101e+00, -9.5860e-01],\n",
       "           [-9.7127e-01, -1.3404e+00, -1.4655e+00,  ..., -9.1189e-01,\n",
       "            -1.0619e+00, -9.5995e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-7.0384e-07, -9.5209e-07, -9.0874e-07,  ..., -1.3645e-06,\n",
       "            -1.7650e-06, -1.1770e-06],\n",
       "           [-1.0874e-06, -1.4586e-06, -1.3409e-06,  ..., -1.9001e-06,\n",
       "            -2.4491e-06, -1.6255e-06],\n",
       "           [-6.9587e-07, -1.0553e-06, -1.2066e-06,  ..., -1.9402e-06,\n",
       "            -2.5267e-06, -1.7145e-06],\n",
       "           ...,\n",
       "           [ 1.3841e-06,  1.8228e-06,  1.8501e-06,  ...,  1.7657e-06,\n",
       "             1.7952e-06,  1.1254e-06],\n",
       "           [ 1.6300e-06,  2.1894e-06,  2.2064e-06,  ...,  1.6827e-06,\n",
       "             1.8105e-06,  1.1513e-06],\n",
       "           [ 1.0899e-06,  1.3817e-06,  1.4222e-06,  ...,  1.0594e-06,\n",
       "             1.1394e-06,  6.8977e-07]],\n",
       " \n",
       "          [[ 4.0783e-07,  3.6144e-07,  3.3896e-07,  ...,  1.0270e-06,\n",
       "             1.0766e-06,  2.8377e-07],\n",
       "           [ 5.3487e-07,  4.7462e-07,  3.7047e-07,  ...,  1.1515e-06,\n",
       "             1.2744e-06,  3.1197e-07],\n",
       "           [ 2.4438e-07,  3.6029e-07,  3.5885e-07,  ...,  1.1864e-06,\n",
       "             1.3583e-06,  3.3273e-07],\n",
       "           ...,\n",
       "           [-8.3426e-07, -8.3437e-07, -8.6361e-07,  ..., -7.7495e-07,\n",
       "            -7.8631e-07, -1.5572e-07],\n",
       "           [-9.8792e-07, -1.0066e-06, -1.0393e-06,  ..., -7.6307e-07,\n",
       "            -7.9830e-07, -1.6095e-07],\n",
       "           [-5.2288e-07, -4.8842e-07, -5.1634e-07,  ..., -3.8972e-07,\n",
       "            -3.8543e-07,  1.6280e-09]],\n",
       " \n",
       "          [[ 3.8261e-05,  4.0369e-05,  4.4077e-05,  ...,  1.2667e-04,\n",
       "             1.7777e-04,  1.2648e-04],\n",
       "           [ 5.3184e-05,  4.7452e-05,  4.1254e-05,  ...,  1.9351e-04,\n",
       "             2.5200e-04,  1.7418e-04],\n",
       "           [ 2.8418e-05,  2.9035e-05,  2.7913e-05,  ...,  1.8993e-04,\n",
       "             2.5125e-04,  1.7818e-04],\n",
       "           ...,\n",
       "           [-1.3924e-04, -1.5750e-04, -1.5946e-04,  ..., -1.3117e-04,\n",
       "            -1.3339e-04, -8.6912e-05],\n",
       "           [-1.4867e-04, -1.7127e-04, -1.7241e-04,  ..., -1.3015e-04,\n",
       "            -1.3629e-04, -8.8920e-05],\n",
       "           [-1.2188e-04, -1.4077e-04, -1.4554e-04,  ..., -9.3732e-05,\n",
       "            -1.0287e-04, -6.7223e-05]]]], grad_fn=<ThnnConv2DBackward>),\n",
       " torch.Size([1, 64, 32, 32]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value1 = vgg19.features[0](data1)\n",
    "value1, value1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 torch.Size([1, 64, 32, 32])\n",
      "5 torch.Size([1, 64, 32, 32])\n",
      "9 torch.Size([1, 128, 16, 16])\n",
      "12 torch.Size([1, 128, 16, 16])\n",
      "16 torch.Size([1, 256, 8, 8])\n",
      "19 torch.Size([1, 256, 8, 8])\n",
      "22 torch.Size([1, 256, 8, 8])\n",
      "25 torch.Size([1, 256, 8, 8])\n",
      "29 torch.Size([1, 512, 4, 4])\n",
      "32 torch.Size([1, 512, 4, 4])\n",
      "35 torch.Size([1, 512, 4, 4])\n",
      "38 torch.Size([1, 512, 4, 4])\n",
      "42 torch.Size([1, 512, 2, 2])\n",
      "45 torch.Size([1, 512, 2, 2])\n",
      "48 torch.Size([1, 512, 2, 2])\n",
      "51 torch.Size([1, 512, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "vgg19.eval()\n",
    "for idx, m in enumerate(vgg19.features):\n",
    "    data1 = m(data1)\n",
    "    if isinstance(m, nn.ReLU):\n",
    "        print(idx, data1.shape)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python37] *",
   "language": "python",
   "name": "conda-env-python37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
