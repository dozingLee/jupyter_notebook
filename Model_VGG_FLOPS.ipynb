{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  VGG FLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "default_cfg = {\n",
    "    11: [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512],\n",
    "    13: [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512],\n",
    "    16: [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512],\n",
    "    19: [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512],\n",
    "}\n",
    "\n",
    "\n",
    "def make_layers(cfg):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1, bias=False)\n",
    "            layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class vgg(nn.Module):\n",
    "    def __init__(self, dataset='cifar10', depth=19, cfg=None, conv_cfg=None):\n",
    "        \"\"\"\n",
    "        note: default initialize weight & have batch normalization\n",
    "\n",
    "        :param dataset: `cifar10` or `cifar100`\n",
    "        :param depth: `11`, `13`, '16', or `19` (default)\n",
    "        :param cfg: vgg model convolutional layer's channel config\n",
    "        :param conv_cfg:\n",
    "            like [2, 4, 8, 12]\n",
    "            return convolutional layer's channel config (index starts at 1)\n",
    "\n",
    "        \"\"\"\n",
    "        super(vgg, self).__init__()\n",
    "\n",
    "        # model value\n",
    "        self.conv_cfg = conv_cfg\n",
    "\n",
    "        # model config\n",
    "        if cfg is None:\n",
    "            cfg = default_cfg[depth]\n",
    "\n",
    "        # model feature\n",
    "        self.feature = make_layers(cfg)\n",
    "\n",
    "        # model classifier\n",
    "        if dataset == 'cifar10':\n",
    "            num_classes = 10\n",
    "        elif dataset == 'cifar100':\n",
    "            num_classes = 100\n",
    "        else:\n",
    "            raise ValueError('Model `dataset` parameter is Error!')\n",
    "        self.classifier = nn.Linear(cfg[-1], num_classes)\n",
    "\n",
    "        # model initialize weight\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(0.5)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # model feature\n",
    "        conv_value = []\n",
    "        if self.conv_cfg:\n",
    "            conv_idx = 0\n",
    "            for k, m in enumerate(self.feature):\n",
    "                x = m(x)\n",
    "                if isinstance(m, nn.Conv2d):\n",
    "                    conv_idx += 1\n",
    "                    if conv_idx in self.conv_cfg:\n",
    "                        conv_value.append(x.clone())\n",
    "        else:\n",
    "            x = self.feature(x)\n",
    "\n",
    "        # model classifier\n",
    "        x = nn.AvgPool2d(2)(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y = self.classifier(x)\n",
    "\n",
    "        # return value\n",
    "        if len(conv_value):\n",
    "            return y, conv_value\n",
    "        return y\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     net = vgg(conv_cfg=[2, 4, 8, 12])\n",
    "#     input = Variable(torch.FloatTensor(64, 3, 32, 32))\n",
    "#     output, value = net(input)\n",
    "#     print('y.data.shape: {}, value length: {}'.format(input.data.shape, len(value)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'D:\\Project\\Gitee\\network-slimming\\logs\\at_prune_vgg19_cifar100_percent_0.5\\pruned.pt'\n",
      "-> model cfg is loading...\n",
      " cfg: [21, 59, 'M', 107, 125, 'M', 241, 229, 203, 205, 'M', 309, 239, 142, 171, 'M', 153, 143, 166, 238]\n",
      "=>  epoch None Prec1: None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def resume_model(resume_file):\n",
    "    if not os.path.isfile(resume_file):\n",
    "        raise ValueError(\"Resume model file is not found at '{}'\".format(resume_file))\n",
    "    print(\"=> loading checkpoint '{}'\".format(resume_file))\n",
    "    checkpoint = torch.load(resume_file)\n",
    "    if 'epoch' in checkpoint:\n",
    "        start_epoch = checkpoint['epoch']\n",
    "    else:\n",
    "        start_epoch = None\n",
    "        \n",
    "    if 'best_prec1' in checkpoint:\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "    else:\n",
    "        best_prec1 = None\n",
    "        \n",
    "    if 'state_dict' in checkpoint:\n",
    "        state_dict = checkpoint['state_dict']\n",
    "    else:\n",
    "        state_dict = None\n",
    "    \n",
    "    if 'optimizer' in checkpoint:\n",
    "        opti_dict = checkpoint['optimizer']\n",
    "    else:\n",
    "        opti_dict = None\n",
    "        \n",
    "    if 'cfg' in checkpoint:\n",
    "        cfg = checkpoint['cfg']\n",
    "        print(\"-> model cfg is loading...\\n cfg: {}\".format(list(cfg)))\n",
    "    else:\n",
    "        cfg = None\n",
    "        print(\"-> not found model cfg...\")\n",
    "    print(\"=>  epoch {} Prec1: {}\".format(start_epoch, best_prec1))\n",
    "    return state_dict, opti_dict, start_epoch, best_prec1, cfg\n",
    "\n",
    "\n",
    "data_path = {\n",
    "    'root': r'D:\\Project\\Gitee\\network-slimming\\logs',\n",
    "    'bn': [\n",
    "        'bn_prune_vgg19_cifar10_percent_0.7',\n",
    "        'bn_prune_vgg19_cifar100_percent_0.5',\n",
    "    ],\n",
    "    'at': [\n",
    "        'at_prune_vgg19_cifar10_percent_0.7',\n",
    "        'at_prune_vgg19_cifar100_percent_0.5',\n",
    "    ],\n",
    "    'flie': 'model_best.pt',\n",
    "    'file2': 'model_best.pth.tar',\n",
    "    'file3': 'pruned.pt',\n",
    "}\n",
    "\n",
    "\n",
    "file_path = os.path.join(data_path['root'], data_path['at'][1], data_path['file3'])\n",
    "state_dict, opti_dict, start_epoch, best_prec1, cfg = resume_model(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vgg(\n",
       "  (feature): Sequential(\n",
       "    (0): Conv2d(3, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(21, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(59, 107, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (8): BatchNorm2d(107, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(107, 125, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (11): BatchNorm2d(125, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(125, 241, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (15): BatchNorm2d(241, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(241, 229, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (18): BatchNorm2d(229, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(229, 203, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (21): BatchNorm2d(203, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(203, 205, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (24): BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (27): Conv2d(205, 309, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (28): BatchNorm2d(309, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(309, 239, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (31): BatchNorm2d(239, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): Conv2d(239, 142, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (34): BatchNorm2d(142, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): Conv2d(142, 171, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (37): BatchNorm2d(171, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (38): ReLU(inplace=True)\n",
       "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (40): Conv2d(171, 153, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (41): BatchNorm2d(153, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): Conv2d(153, 143, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (44): BatchNorm2d(143, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (45): ReLU(inplace=True)\n",
       "    (46): Conv2d(143, 166, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (47): BatchNorm2d(166, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (48): ReLU(inplace=True)\n",
       "    (49): Conv2d(166, 238, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (50): BatchNorm2d(238, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (51): ReLU(inplace=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=238, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = vgg(depth=19, dataset='cifar100', cfg=cfg, conv_cfg=None)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      module name  input shape output shape     params memory(MB)           MAdd          Flops  MemRead(B)  MemWrite(B) duration[%]   MemR+W(B)\n",
      "0       feature.0    3  32  32   21  32  32      567.0       0.08    1,139,712.0      580,608.0     14556.0      86016.0       0.00%    100572.0\n",
      "1       feature.1   21  32  32   21  32  32       42.0       0.08       86,016.0       43,008.0     86184.0      86016.0       0.00%    172200.0\n",
      "2       feature.2   21  32  32   21  32  32        0.0       0.08       21,504.0       21,504.0     86016.0      86016.0       0.00%    172032.0\n",
      "3       feature.3   21  32  32   59  32  32    11151.0       0.23   22,776,832.0   11,418,624.0    130620.0     241664.0       0.00%    372284.0\n",
      "4       feature.4   59  32  32   59  32  32      118.0       0.23      241,664.0      120,832.0    242136.0     241664.0       0.00%    483800.0\n",
      "5       feature.5   59  32  32   59  32  32        0.0       0.23       60,416.0       60,416.0    241664.0     241664.0       0.00%    483328.0\n",
      "6       feature.6   59  32  32   59  16  16        0.0       0.06       45,312.0       60,416.0    241664.0      60416.0       0.00%    302080.0\n",
      "7       feature.7   59  16  16  107  16  16    56817.0       0.10   29,062,912.0   14,545,152.0    287684.0     109568.0       0.00%    397252.0\n",
      "8       feature.8  107  16  16  107  16  16      214.0       0.10      109,568.0       54,784.0    110424.0     109568.0       0.00%    219992.0\n",
      "9       feature.9  107  16  16  107  16  16        0.0       0.10       27,392.0       27,392.0    109568.0     109568.0       0.00%    219136.0\n",
      "10     feature.10  107  16  16  125  16  16   120375.0       0.12   61,600,000.0   30,816,000.0    591068.0     128000.0      33.24%    719068.0\n",
      "11     feature.11  125  16  16  125  16  16      250.0       0.12      128,000.0       64,000.0    129000.0     128000.0       0.00%    257000.0\n",
      "12     feature.12  125  16  16  125  16  16        0.0       0.12       32,000.0       32,000.0    128000.0     128000.0       0.00%    256000.0\n",
      "13     feature.13  125  16  16  125   8   8        0.0       0.03       24,000.0       32,000.0    128000.0      32000.0       0.00%    160000.0\n",
      "14     feature.14  125   8   8  241   8   8   271125.0       0.06   34,688,576.0   17,352,000.0   1116500.0      61696.0       0.00%   1178196.0\n",
      "15     feature.15  241   8   8  241   8   8      482.0       0.06       61,696.0       30,848.0     63624.0      61696.0       0.00%    125320.0\n",
      "16     feature.16  241   8   8  241   8   8        0.0       0.06       15,424.0       15,424.0     61696.0      61696.0       0.00%    123392.0\n",
      "17     feature.17  241   8   8  229   8   8   496701.0       0.06   63,563,072.0   31,788,864.0   2048500.0      58624.0       0.00%   2107124.0\n",
      "18     feature.18  229   8   8  229   8   8      458.0       0.06       58,624.0       29,312.0     60456.0      58624.0       0.00%    119080.0\n",
      "19     feature.19  229   8   8  229   8   8        0.0       0.06       14,656.0       14,656.0     58624.0      58624.0       0.00%    117248.0\n",
      "20     feature.20  229   8   8  203   8   8   418383.0       0.05   53,540,032.0   26,776,512.0   1732156.0      51968.0      33.37%   1784124.0\n",
      "21     feature.21  203   8   8  203   8   8      406.0       0.05       51,968.0       25,984.0     53592.0      51968.0       0.00%    105560.0\n",
      "22     feature.22  203   8   8  203   8   8        0.0       0.05       12,992.0       12,992.0     51968.0      51968.0       0.00%    103936.0\n",
      "23     feature.23  203   8   8  205   8   8   374535.0       0.05   47,927,360.0   23,970,240.0   1550108.0      52480.0       0.00%   1602588.0\n",
      "24     feature.24  205   8   8  205   8   8      410.0       0.05       52,480.0       26,240.0     54120.0      52480.0       0.00%    106600.0\n",
      "25     feature.25  205   8   8  205   8   8        0.0       0.05       13,120.0       13,120.0     52480.0      52480.0       0.00%    104960.0\n",
      "26     feature.26  205   8   8  205   4   4        0.0       0.01        9,840.0       13,120.0     52480.0      13120.0       0.00%     65600.0\n",
      "27     feature.27  205   4   4  309   4   4   570105.0       0.02   18,238,416.0    9,121,680.0   2293540.0      19776.0       0.00%   2313316.0\n",
      "28     feature.28  309   4   4  309   4   4      618.0       0.02       19,776.0        9,888.0     22248.0      19776.0       0.00%     42024.0\n",
      "29     feature.29  309   4   4  309   4   4        0.0       0.02        4,944.0        4,944.0     19776.0      19776.0       0.00%     39552.0\n",
      "30     feature.30  309   4   4  239   4   4   664659.0       0.01   21,265,264.0   10,634,544.0   2678412.0      15296.0      33.39%   2693708.0\n",
      "31     feature.31  239   4   4  239   4   4      478.0       0.01       15,296.0        7,648.0     17208.0      15296.0       0.00%     32504.0\n",
      "32     feature.32  239   4   4  239   4   4        0.0       0.01        3,824.0        3,824.0     15296.0      15296.0       0.00%     30592.0\n",
      "33     feature.33  239   4   4  142   4   4   305442.0       0.01    9,771,872.0    4,887,072.0   1237064.0       9088.0       0.00%   1246152.0\n",
      "34     feature.34  142   4   4  142   4   4      284.0       0.01        9,088.0        4,544.0     10224.0       9088.0       0.00%     19312.0\n",
      "35     feature.35  142   4   4  142   4   4        0.0       0.01        2,272.0        2,272.0      9088.0       9088.0       0.00%     18176.0\n",
      "36     feature.36  142   4   4  171   4   4   218538.0       0.01    6,990,480.0    3,496,608.0    883240.0      10944.0       0.00%    894184.0\n",
      "37     feature.37  171   4   4  171   4   4      342.0       0.01       10,944.0        5,472.0     12312.0      10944.0       0.00%     23256.0\n",
      "38     feature.38  171   4   4  171   4   4        0.0       0.01        2,736.0        2,736.0     10944.0      10944.0       0.00%     21888.0\n",
      "39     feature.39  171   4   4  171   2   2        0.0       0.00        2,052.0        2,736.0     10944.0       2736.0       0.00%     13680.0\n",
      "40     feature.40  171   2   2  153   2   2   235467.0       0.00    1,883,124.0      941,868.0    944604.0       2448.0       0.00%    947052.0\n",
      "41     feature.41  153   2   2  153   2   2      306.0       0.00        2,448.0        1,224.0      3672.0       2448.0       0.00%      6120.0\n",
      "42     feature.42  153   2   2  153   2   2        0.0       0.00          612.0          612.0      2448.0       2448.0       0.00%      4896.0\n",
      "43     feature.43  153   2   2  143   2   2   196911.0       0.00    1,574,716.0      787,644.0    790092.0       2288.0       0.00%    792380.0\n",
      "44     feature.44  143   2   2  143   2   2      286.0       0.00        2,288.0        1,144.0      3432.0       2288.0       0.00%      5720.0\n",
      "45     feature.45  143   2   2  143   2   2        0.0       0.00          572.0          572.0      2288.0       2288.0       0.00%      4576.0\n",
      "46     feature.46  143   2   2  166   2   2   213642.0       0.00    1,708,472.0      854,568.0    856856.0       2656.0       0.00%    859512.0\n",
      "47     feature.47  166   2   2  166   2   2      332.0       0.00        2,656.0        1,328.0      3984.0       2656.0       0.00%      6640.0\n",
      "48     feature.48  166   2   2  166   2   2        0.0       0.00          664.0          664.0      2656.0       2656.0       0.00%      5312.0\n",
      "49     feature.49  166   2   2  238   2   2   355572.0       0.00    2,843,624.0    1,422,288.0   1424944.0       3808.0       0.00%   1428752.0\n",
      "50     feature.50  238   2   2  238   2   2      476.0       0.00        3,808.0        1,904.0      5712.0       3808.0       0.00%      9520.0\n",
      "51     feature.51  238   2   2  238   2   2        0.0       0.00          952.0          952.0      3808.0       3808.0       0.00%      7616.0\n",
      "52     classifier          238          100    23900.0       0.00       47,500.0       23,800.0     96552.0        400.0       0.00%     96952.0\n",
      "total                                        4539392.0       2.55  379,773,568.0  190,168,584.0     96552.0        400.0     100.00%  23521864.0\n",
      "================================================================================================================================================\n",
      "Total params: 4,539,392\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total memory: 2.55MB\n",
      "Total MAdd: 379.77MMAdd\n",
      "Total Flops: 190.17MFlops\n",
      "Total MemR+W: 22.43MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchstat import stat\n",
    "\n",
    "stat(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.vgg'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "189846232.0 4539392.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('189.85M', '4.54M')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from thop import profile\n",
    "from thop import clever_format\n",
    "\n",
    "\n",
    "input = torch.randn(1, 3, 32, 32)\n",
    "flops, params = profile(model, inputs=(input, ))\n",
    "print(flops, params)\n",
    "flops, params = clever_format([flops, params], \"%.2f\")\n",
    "flops, params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python37] *",
   "language": "python",
   "name": "conda-env-python37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
